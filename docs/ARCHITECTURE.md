# 系統架構說明

本文件說明世德會議助理的系統架構設計、模組說明與技術選型理由。

## 目錄

- [系統概觀](#系統概觀)
- [架構圖](#架構圖)
- [模組說明](#模組說明)
- [資料流程](#資料流程)
- [技術選型理由](#技術選型理由)
- [效能最佳化](#效能最佳化)
- [未來擴展方向](#未來擴展方向)

---

## 系統概觀

世德會議助理是一個端到端的會議語音處理系統，採用前後端分離架構，所有 AI 推理皆在本地執行，確保資料隱私。

**系統特點**

- 純本地運算，無雲端依賴
- 模組化設計，易於擴展
- 非同步處理，提升使用體驗
- Apple Silicon 原生優化

---

## 架構圖

### 系統總覽

```
                           +------------------------------------------+
                           |             世德會議助理                   |
                           +------------------------------------------+
                                              |
                                              v
+------------------+       +------------------------------------------+
|                  |       |              Web 層                       |
|    使用者介面     | <---> |   +----------------------------------+   |
|   (瀏覽器)        |       |   |         FastAPI (app.py)         |   |
|                  |  HTTP |   |  - 路由處理                        |   |
+------------------+       |   |  - 檔案上傳                        |   |
                           |   |  - 非同步任務調度                   |   |
                           |   +----------------------------------+   |
                           +------------------------------------------+
                                              |
                         +--------------------+--------------------+
                         |                                         |
                         v                                         v
          +---------------------------+         +---------------------------+
          |      語音轉文字模組         |         |       摘要生成模組          |
          |       (stt.py)            |         |    (summarizer.py)        |
          +---------------------------+         +---------------------------+
          |                           |         |                           |
          | - transcribe()            |         | - summarize()             |
          | - transcribe_with_        |         | - check_ollama_status()   |
          |   timestamps()            |         |                           |
          |                           |         |                           |
          +-------------+-------------+         +-------------+-------------+
                        |                                     |
                        v                                     v
          +---------------------------+         +---------------------------+
          |        mlx-whisper         |         |          Ollama           |
          +---------------------------+         +---------------------------+
          |                           |         |                           |
          | whisper-large-v3-mlx      |         | qwen2.5:14b               |
          | (Apple Silicon 優化)       |         | (本地 LLM 推理)            |
          |                           |         |                           |
          +---------------------------+         +---------------------------+
```

### 請求處理流程

```
使用者上傳音檔
       |
       v
+------+------+
|  檔案驗證    |
+------+------+
       |
       v
+------+------+
| 暫存至磁碟   |
+------+------+
       |
       +-------------+
       |             |
       v             |
+------+------+      |
| 語音轉文字   |      |  (執行緒池非同步執行)
| mlx-whisper |      |
+------+------+      |
       |             |
       v             |
+------+------+      |
| 取得逐字稿   |<-----+
+------+------+
       |
       v
+------+------+
| 摘要生成     |
| Ollama API  |
+------+------+
       |
       v
+------+------+
| 清理暫存檔   |
+------+------+
       |
       v
+------+------+
| 回傳 JSON   |
+------+------+
```

---

## 模組說明

### app.py - Web 應用層

**職責**

- 提供 Web 介面（單頁 HTML 應用）
- 處理檔案上傳與驗證
- 協調 STT 與摘要模組
- 非同步任務排程

**主要元件**

| 元件 | 說明 |
|------|------|
| `FastAPI` | Web 框架實例 |
| `ThreadPoolExecutor` | 執行緒池（max_workers=2） |
| `UPLOAD_DIR` | 暫存檔案目錄 |
| `HTML_TEMPLATE` | 內嵌的前端 HTML |

**API 端點**

| 端點 | 方法 | 說明 |
|------|------|------|
| `/` | GET | 回傳 Web 介面 |
| `/health` | GET | 健康檢查 |
| `/process` | POST | 處理音檔 |

**設計決策**

- 使用內嵌 HTML 而非分離的前端專案，簡化 POC 部署
- 使用 ThreadPoolExecutor 處理 CPU 密集型任務，避免阻塞主執行緒
- 處理完成後自動刪除暫存檔案，避免磁碟空間累積

---

### stt.py - 語音轉文字模組

**職責**

- 載入並執行 Whisper 模型
- 將音檔轉換為文字
- 產生帶時間軸的逐字稿

**主要函式**

```python
def transcribe(audio_path: str, language: str = None) -> dict:
    """
    完整轉錄功能

    回傳:
        {
            "text": "完整文字",
            "language": "zh",
            "segments": [...],
            "timestamped_text": "[00:00 - 00:05] 文字..."
        }
    """

def transcribe_with_timestamps(audio_path: str) -> str:
    """
    只回傳帶時間軸的文字
    """
```

**模型配置**

| 項目 | 值 |
|------|------|
| 模型 | `mlx-community/whisper-large-v3-mlx` |
| 框架 | MLX (Apple Silicon 優化) |
| 語言 | 自動偵測（可手動指定） |

**時間軸格式**

```
[MM:SS - MM:SS] 語音內容
```

---

### summarizer.py - 摘要生成模組

**職責**

- 連接 Ollama API
- 根據風格生成結構化摘要
- 檢查 Ollama 服務狀態

**主要函式**

```python
def summarize(text: str, model: str, style: str) -> str:
    """
    生成摘要

    參數:
        text: 要摘要的文字
        model: Ollama 模型名稱
        style: 摘要風格 (meeting/article/brief)

    回傳:
        Markdown 格式的摘要
    """

def check_ollama_status() -> dict:
    """
    檢查 Ollama 服務狀態

    回傳:
        {
            "available": True/False,
            "models": ["model1", "model2"]
        }
    """
```

**摘要風格**

| 風格 | 輸出格式 |
|------|----------|
| `meeting` | 摘要 + 重點 + 待辦事項 + 決議 |
| `article` | 100 字摘要 + 關鍵詞 |
| `brief` | 3 句話以內 |

**Ollama API 配置**

| 項目 | 值 |
|------|------|
| API URL | `http://localhost:11434/api/generate` |
| 預設模型 | `qwen2.5:14b` |
| Temperature | 0.3 |
| Max Tokens | 2048 |
| Timeout | 120 秒 |

---

## 資料流程

### 完整處理流程

```
1. 使用者上傳
   +-------------------+
   | 音檔 (MP3/WAV/...) |
   +-------------------+
            |
            v
2. 檔案暫存
   +-------------------+
   | /uploads/{uuid}.ext|
   +-------------------+
            |
            v
3. 語音轉文字 (mlx-whisper)
   +-------------------+
   | - 載入模型        |
   | - 音檔解碼        |
   | - 特徵提取        |
   | - 序列解碼        |
   +-------------------+
            |
            v
4. 轉錄結果
   +-------------------+
   | text: "..."       |
   | segments: [...]   |
   | language: "zh"    |
   +-------------------+
            |
            v
5. 摘要生成 (Ollama)
   +-------------------+
   | - 建構 Prompt     |
   | - 呼叫 LLM API    |
   | - 解析回應        |
   +-------------------+
            |
            v
6. 回傳結果
   +-------------------+
   | {                 |
   |   transcript,     |
   |   timestamped,    |
   |   summary,        |
   |   language        |
   | }                 |
   +-------------------+
            |
            v
7. 清理暫存
   +-------------------+
   | 刪除音檔          |
   +-------------------+
```

### 資料格式轉換

```
音檔 (binary)
    |
    | [mlx-whisper 解碼]
    v
音訊波形 (float32 array)
    |
    | [特徵提取]
    v
Mel 頻譜圖 (2D array)
    |
    | [Transformer 解碼]
    v
Token 序列 (int array)
    |
    | [解碼 + 分段]
    v
文字 + 時間軸 (dict)
    |
    | [Prompt 組裝]
    v
LLM Prompt (string)
    |
    | [Ollama 推理]
    v
摘要 (Markdown string)
```

---

## 技術選型理由

### mlx-whisper

| 考量點 | 選擇理由 |
|--------|----------|
| 效能 | 針對 Apple Silicon 優化，比 PyTorch 版本快 2-3 倍 |
| 品質 | 使用 Whisper large-v3，目前最佳的開源語音模型 |
| 相容性 | 原生支援 M1/M2/M3 晶片，無需額外配置 |
| 記憶體 | MLX 框架的惰性執行減少記憶體佔用 |

**比較表**

| 方案 | 速度 | 品質 | 平台支援 |
|------|------|------|----------|
| mlx-whisper | 快 | 高 | Apple Silicon |
| whisper.cpp | 中 | 高 | 跨平台 |
| openai-whisper | 慢 | 高 | 跨平台 |

### Ollama + qwen2.5

| 考量點 | 選擇理由 |
|--------|----------|
| 隱私 | 完全本地執行，資料不外傳 |
| 成本 | 無 API 費用 |
| 中文能力 | Qwen 2.5 系列在中文任務表現優異 |
| 易用性 | Ollama 提供簡單的 API 介面 |

**模型比較**

| 模型 | 中文能力 | 速度 | 記憶體需求 |
|------|----------|------|-----------|
| qwen2.5:14b | 優 | 中 | ~12GB |
| llama3:8b | 良 | 快 | ~8GB |
| mistral:7b | 中 | 快 | ~6GB |

### FastAPI

| 考量點 | 選擇理由 |
|--------|----------|
| 效能 | 基於 Starlette，高效能非同步框架 |
| 開發效率 | 自動生成 OpenAPI 文件 |
| 類型安全 | Pydantic 資料驗證 |
| 生態系 | 豐富的中介軟體與擴展 |

---

## 效能最佳化

### 目前實作的優化

1. **執行緒池非同步處理**
   ```python
   executor = ThreadPoolExecutor(max_workers=2)
   result = await loop.run_in_executor(executor, transcribe, file_path)
   ```
   - 避免阻塞主執行緒
   - 保持 Web 介面回應性

2. **自動清理暫存檔**
   ```python
   finally:
       if file_path.exists():
           file_path.unlink()
   ```
   - 處理完成後立即刪除
   - 避免磁碟空間累積

3. **Ollama 參數調優**
   ```python
   "options": {
       "temperature": 0.3,  # 降低隨機性
       "num_predict": 2048  # 限制輸出長度
   }
   ```

### 建議的進階優化

| 優化項目 | 說明 | 預期效果 |
|----------|------|----------|
| 串流輸出 | 使用 SSE 即時回傳進度 | 改善使用者體驗 |
| 音檔分段 | 長音檔切分後並行處理 | 加速長音檔處理 |
| 模型快取 | 預載入模型到記憶體 | 減少首次延遲 |
| 結果快取 | 相同音檔快取結果 | 避免重複處理 |

---

## 未來擴展方向

### 短期改進

- [ ] 支援即時錄音（WebRTC）
- [ ] 新增說話者辨識（Speaker Diarization）
- [ ] 支援多種輸出格式（SRT、VTT）
- [ ] 串流式處理進度顯示

### 中期目標

- [ ] 支援 Intel Mac（使用 whisper.cpp）
- [ ] 多語言介面
- [ ] 批次處理功能
- [ ] 會議排程整合（Google Calendar）

### 長期願景

- [ ] 支援 Windows/Linux（跨平台）
- [ ] 雲端版本（可選）
- [ ] 會議洞察分析（情緒、關鍵人物）
- [ ] 團隊協作功能

---

## 附錄：元件版本

| 元件 | 版本 |
|------|------|
| Python | 3.9+ |
| FastAPI | 0.100+ |
| mlx-whisper | 0.4.0+ |
| Ollama | 最新 |
| Whisper 模型 | large-v3 |
| LLM 模型 | qwen2.5:14b |
